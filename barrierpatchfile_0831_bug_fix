diff --git kernel/x86_64/block/blk-core.c kernel/x86_64/block/blk-core.c
index 3ca326a..57e0739 100755
--- kernel/x86_64/block/blk-core.c
+++ kernel/x86_64/block/blk-core.c
@@ -766,7 +766,7 @@ blk_set_epoch_pool(struct request_queue *q)
 	mutex_init(&q->epoch_id_lock);
 	q->epoch_id = 0;
 	q->epoch_complete = false;
-
+	q->flush_flags |= REQ_FLUSH; // Jieun add
 	return q;
 }
 EXPORT_SYMBOL(blk_set_epoch_pool);
@@ -1847,13 +1847,14 @@ generic_make_request_checks(struct bio *bio)
 	 * drivers without flush support don't have to worry
 	 * about them.
 	 */
+	/*
 	if ((bio->bi_rw & (REQ_FLUSH | REQ_FUA)) && !q->flush_flags) {
 		bio->bi_rw &= ~(REQ_FLUSH | REQ_FUA);
 		if (!nr_sectors) {
 			err = 0;
 			goto end_io;
 		}
-	}
+	}*/
 
 	if ((bio->bi_rw & REQ_DISCARD) &&
 	    (!blk_queue_discard(q) ||
@@ -2012,6 +2013,8 @@ void submit_bio(long long/*int*/ rw, struct bio *bio)
 		 * Original is in blk_queue_bio() for scsi
 		 */
 		if (bio->bi_rw & REQ_ORDERED) {
+
+
 			struct request_queue *q = bdev_get_queue(bio->bi_bdev);
 			if (!current->__epoch)
 				blk_start_epoch(q);
@@ -2019,16 +2022,10 @@ void submit_bio(long long/*int*/ rw, struct bio *bio)
 			get_epoch(current->__epoch);
 			bio->bi_epoch = current->__epoch;
 			bio->bi_epoch->pending++;
-			mutex_lock(&q->epoch_id_lock);
-			g_epoch_id = bio->bi_epoch->eid;
-			mutex_unlock(&q->epoch_id_lock);
-
+			
 			if (bio->bi_rw & REQ_BARRIER) {
 				blk_finish_epoch();
-
-				mutex_lock(&q->epoch_id_lock);
-				q->epoch_complete = true;
-				mutex_unlock(&q->epoch_id_lock);
+				current->epoch_count++;
 			}
 		}
 		/* end */
@@ -2071,6 +2068,7 @@ void submit_bio64(long long rw, struct bio *bio)
 
 		/* kms91 added */
 		if (bio->bi_rw & REQ_ORDERED) {
+
 			struct request_queue *q = bdev_get_queue(bio->bi_bdev);
 			if (!current->__epoch)
 				blk_start_epoch(q);
@@ -2078,16 +2076,10 @@ void submit_bio64(long long rw, struct bio *bio)
 			get_epoch(current->__epoch);
 			bio->bi_epoch = current->__epoch;
 			bio->bi_epoch->pending++;
-			mutex_lock(&q->epoch_id_lock);
-			g_epoch_id = bio->bi_epoch->eid;
-			mutex_unlock(&q->epoch_id_lock);
-
+			
 			if (bio->bi_rw & REQ_BARRIER) {
 				blk_finish_epoch();
-
-				mutex_lock(&q->epoch_id_lock);
-				q->epoch_complete = true;
-				mutex_unlock(&q->epoch_id_lock);
+				current->epoch_count++;
 			}
 		}
 	}
@@ -3361,6 +3353,7 @@ void blk_start_epoch(struct request_queue *q)
 	 * If epoch id is bigger than UINT_MAX, it initialize to zero.
 	 * And epoch id is insert into global var for blktrace.
 	 */
+	/* Jieun Modified
 	mutex_lock(&q->epoch_id_lock);
 	if(q->epoch_complete) {
 		if(q->epoch_id == UINT_MAX)
@@ -3372,7 +3365,7 @@ void blk_start_epoch(struct request_queue *q)
 		epoch->eid = q->epoch_id;
 
 	mutex_unlock(&q->epoch_id_lock);
-
+	*/
 	get_epoch(epoch);
 
 	current->__epoch = epoch;	
diff --git kernel/x86_64/drivers/block/nvme-core.c kernel/x86_64/drivers/block/nvme-core.c
index b5760d7..3bace04 100755
--- kernel/x86_64/drivers/block/nvme-core.c
+++ kernel/x86_64/drivers/block/nvme-core.c
@@ -725,13 +725,19 @@ static int nvme_submit_bio_queue(struct nvme_queue *nvmeq, struct nvme_ns *ns,
 	 * type of cmd_epoch_id in nvme cmd is __u32(unsigned int). 
 	 * So it is inserted directly without typecasting.
 	 */
+
+
 	if(bio->bi_epoch) {
-		cmnd->rw.cmd_stream_id = bio->bi_stream_id;
-		cmnd->rw.cmd_epoch_id = bio->bi_epoch->eid;
+		cmnd->rw.sid_1 = bio->stream_id_1;
+		cmnd->rw.sid_2 = bio->stream_id_2;
+		cmnd->rw.eid_1 = bio->epoch_id_1;
+		cmnd->rw.eid_2 = bio->epoch_id_2;
 	}
 	else {
-		cmnd->rw.cmd_stream_id = 0;
-		cmnd->rw.cmd_epoch_id = 0;
+		cmnd->rw.sid_1 = 0;
+		cmnd->rw.sid_2 = 0;
+		cmnd->rw.eid_1 = 0;
+		cmnd->rw.eid_2 = 0;
 	}
 
 	if (++nvmeq->sq_tail == nvmeq->q_depth)
@@ -760,9 +766,28 @@ static int nvme_submit_bio_queue(struct nvme_queue *nvmeq, struct nvme_ns *ns,
 static void nvme_make_request(struct request_queue *q, struct bio *bio)
 {
 	struct nvme_ns *ns = q->queuedata;
-	struct nvme_queue *nvmeq = get_nvmeq(ns->dev);
+	//struct nvme_queue *nvmeq = get_nvmeq(ns->dev);
+	struct nvme_queue *nvmeq;
 	int result = -EBUSY;
-
+	if (bio->bi_rw & REQ_ORDERED) {
+		if(current->queue_idx == -1){
+			nvmeq = get_nvmeq(ns->dev);
+			current->queue_idx = get_cpu()+1;
+		}
+		else {
+			nvmeq = ns->dev->queues[current->queue_idx];
+		}
+		if (bio->bi_rw & REQ_BARRIER){
+			current->queue_idx = -1;
+		}
+	}
+	else {
+		nvmeq = get_nvmeq(ns->dev);
+	}
+	/*
+	if (bio->bi_rw & REQ_FLUSH){
+		printk("NVMe make request REQ_FLUSH\t stream id:%ld\t epoch id:%ld\n", bio->stream_id_1, bio->epoch_id_1);
+	}*/
 	spin_lock_irq(&nvmeq->q_lock);
 	if (bio_list_empty(&nvmeq->sq_cong))
 		result = nvme_submit_bio_queue(nvmeq, ns, bio);
@@ -1554,8 +1579,7 @@ static int nvme_kthread(void *data)
 				if (!nvmeq)
 					continue;
 				spin_lock_irq(&nvmeq->q_lock);
-				if (nvme_process_cq(nvmeq))
-					printk("process_cq did something\n");
+				nvme_process_cq(nvmeq);
 				nvme_cancel_ios(nvmeq, true);
 				nvme_resubmit_bios(nvmeq);
 				spin_unlock_irq(&nvmeq->q_lock);
diff --git kernel/x86_64/fs/buffer.c kernel/x86_64/fs/buffer.c
index 4c0c048..faa01ab 100755
--- kernel/x86_64/fs/buffer.c
+++ kernel/x86_64/fs/buffer.c
@@ -3116,13 +3116,10 @@ int _submit_bh64(long long rw, struct buffer_head *bh, unsigned long long bio_fl
 	bio->bi_end_io = end_bio_bh_io_sync;
 	bio->bi_private = bh;
 
-	/*
-	 * kms91 added 19.04.05
-	 * Initialize bi_stream_id. bi_stream_id store current process id.
-	 * Type of bi_stream_id is pid_t,
-	 * so it is not necessary to type casting.
-	 */
-	bio->bi_stream_id = current->pid;
+	bio->stream_id_1 = current->pid;
+	bio->stream_id_2 = 0;
+	bio->epoch_id_1 = current->epoch_count;
+	bio->epoch_id_2 = 0;
 
 	/* Take care of bh's that straddle the end of the device */
 	guard_bh_eod(rw, bio, bh);
diff --git kernel/x86_64/fs/ext4/fsync.c kernel/x86_64/fs/ext4/fsync.c
index 657d3a7..8d16ab7 100755
--- kernel/x86_64/fs/ext4/fsync.c
+++ kernel/x86_64/fs/ext4/fsync.c
@@ -123,14 +123,15 @@ int ext4_sync_file(struct file *file, loff_t start, loff_t end, int datasync)
 	J_ASSERT(ext4_journal_current_handle() == NULL);
 
 	trace_ext4_sync_file_enter(file, datasync);
-
+	/*
 	if (datasync) {
 	  // current->barrier_fail = 0;
-	        ret = filemap_write_and_wait_range(inode->i_mapping, start, end);
-	        //ret = filemap_ordered_write_range(inode->i_mapping, start, end);
+	  // ret = filemap_write_and_wait_range(inode->i_mapping, start, end);
+	  	ret = filemap_ordered_write_range(inode->i_mapping, start, end);
+			ret = filemap_fdatadispatch_range(inode->i_mapping, start, end); //Jieun add
 		//ret = filemap_fdatawait_range(inode->i_mapping, start, end);
 	}
-	else
+	else*/
 	        ret = filemap_write_and_dispatch_range(inode->i_mapping, start, end);
 
 	//      ret = filemap_ordered_write_range(inode->i_mapping, start, end);
@@ -183,7 +184,8 @@ int ext4_sync_file(struct file *file, loff_t start, loff_t end, int datasync)
 	ret = jbd2_complete_cpsetup_transaction(journal, commit_tid);
 	
 	if (needs_barrier) {
-		filemap_fdatawait_range(inode->i_mapping, start, end);
+		//filemap_fdatawait_range(inode->i_mapping, start, end);	// for the sake of Queue pinning
+		//filemap_fdatadispatch_range(inode->i_mapping, start, end); //Jieun add
 		err = blkdev_issue_flush(inode->i_sb->s_bdev, GFP_KERNEL, NULL);
 		if (!ret)
 			ret = err;
@@ -211,7 +213,7 @@ int ext4_fbarrier_file(struct file *file, loff_t start, loff_t end, int datasync
 	J_ASSERT(ext4_journal_current_handle() == NULL);
 
 	trace_ext4_sync_file_enter(file, datasync);
-
+	/*
 	if (datasync) {
 		current->barrier_fail = 0;
 		ret = filemap_ordered_write_range(inode->i_mapping, start, end);
@@ -221,6 +223,10 @@ int ext4_fbarrier_file(struct file *file, loff_t start, loff_t end, int datasync
 	}
 	else
 		ret = filemap_write_and_dispatch_range(inode->i_mapping, start, end);
+	*/
+	/* Jieun add */
+	ret = filemap_ordered_write_range(inode->i_mapping, start, end);
+	ret = filemap_fdatadispatch_range(inode->i_mapping, start, end);
 
 	if (ret)
 		return ret;
diff --git kernel/x86_64/fs/ext4/inode.c kernel/x86_64/fs/ext4/inode.c
index a5d4be8..9636165 100755
--- kernel/x86_64/fs/ext4/inode.c
+++ kernel/x86_64/fs/ext4/inode.c
@@ -1552,7 +1552,16 @@ static int mpage_da_submit_io(struct mpage_da_data *mpd,
 				unlock_page(page);
 				continue;
 			}
-
+			// Jieun add
+			// last dirty page IO should become barrier-write	
+			handle_t *handle =  ext4_journal_current_handle();
+			if((mpd->wbc->sync_mode == WB_ORDERED_ALL || mpd->wbc->sync_mode == WB_BARRIER_ALL) && i == nr_pages-1){	
+				//printk(KERN_ERR "mpage_da_submit_io current pid:%d\t j_task pid: %d\n", current->pid, handle->h_transaction->t_journal->j_task->pid);
+				if(current->pid != handle->h_transaction->t_journal->j_task->pid){			
+					io_submit.io_op = WRITE_BARRIER;
+					//printk(KERN_ERR "PID: %d\t barrier-write set\n", current->pid);
+				}
+			}
 			clear_page_dirty_for_io(page);
 			err = ext4_bio_write_page(&io_submit, page, len,
 						  mpd->wbc);
@@ -2592,9 +2601,9 @@ retry:
 			break;
 	}
 	/* UFS */
-	if (wbc->sync_mode == WB_BARRIER_ALL) {
-		blk_issue_barrier_plug(&plug);
-	}
+	//if (wbc->sync_mode == WB_BARRIER_ALL) {
+	//	blk_issue_barrier_plug(&plug);
+	//}
 
 	blk_finish_plug(&plug);
 	if (!io_done && !cycled) {
diff --git kernel/x86_64/fs/ext4/page-io.c kernel/x86_64/fs/ext4/page-io.c
index 112cc5d..0b046e6 100755
--- kernel/x86_64/fs/ext4/page-io.c
+++ kernel/x86_64/fs/ext4/page-io.c
@@ -327,22 +327,35 @@ static int io_submit_init(struct ext4_io_submit *io,
 	bio->bi_bdev = bh->b_bdev;
 	bio->bi_private = io->io_end = io_end;
 	bio->bi_end_io = ext4_end_bio;
+	
+	/* Jieun add */
+	bio->stream_id_1 = current->pid;
+	bio->epoch_id_2 = 0;
+	bio->stream_id_2 = 0;
+
+	handle_t *handle =  ext4_journal_current_handle();
+	if(wbc->sync_mode == WB_ORDERED_ALL){
+		bio->epoch_id_1 = current->epoch_count;
+		if(handle!=NULL){
+			bio->stream_id_2 = handle->h_transaction->t_journal->j_task->pid;
+			bio->epoch_id_2 = handle->h_transaction->t_journal->j_task->epoch_count;
+		}
+	}
+	else if(wbc->sync_mode == WB_BARRIER_ALL){
 
-	/* 
-	 * kms91 added 19.04.05
-	 * Initialize bi_stream_id. bi_stream_id store current process id.
-	 * Type of bi_stream_id is pid_t, 
-	 * so it is not necessary to type casting.
-	 */
-	bio->bi_stream_id = current->pid;
-
-
+		bio->epoch_id_1 = current->epoch_count;
+		if(handle->h_transaction->t_tid == EXT4_I(inode)->i_datasync_tid){
+			// Journaling will be performed
+			bio->stream_id_2 = handle->h_transaction->t_journal->j_task->pid;
+			bio->epoch_id_2 = handle->h_transaction->t_journal->j_task->epoch_count;
+		}
+	}
 	io_end->offset = (page->index << PAGE_CACHE_SHIFT) + bh_offset(bh);
 
 	io->io_bio = bio;
-	io->io_op = (wbc->sync_mode == WB_SYNC_ALL ?  WRITE_SYNC : WRITE);
+	//io->io_op = (wbc->sync_mode == WB_SYNC_ALL ?  WRITE_SYNC : WRITE);
 	/* UFS */
-	
+		
 	switch (wbc->sync_mode) {
 	case WB_SYNC_ALL:
 		io->io_op = WRITE_SYNC;
@@ -351,10 +364,16 @@ static int io_submit_init(struct ext4_io_submit *io,
 		io->io_op = WRITE;
 		break;
 	case WB_ORDERED_ALL:
+		if(io->io_op == WRITE_BARRIER){
+			//break;
+			current->epoch_count++;
+		}
 		io->io_op = WRITE_ORDERED;
 		break;
 	case WB_BARRIER_ALL:
-		io->io_op = WRITE_ORDERED;
+		if(io->io_op != WRITE_BARRIER){
+			io->io_op = WRITE_ORDERED;
+		}
 		break;
 	}
 	
diff --git kernel/x86_64/fs/jbd2/commit.c kernel/x86_64/fs/jbd2/commit.c
index a05fc83..7c0b158 100755
--- kernel/x86_64/fs/jbd2/commit.c
+++ kernel/x86_64/fs/jbd2/commit.c
@@ -1961,8 +1961,11 @@ start_journal_io:
 			commit_transaction;
 	}
 	spin_unlock(&journal->j_cplist_lock);
-
-	wake_up(&journal->j_wait_cpsetup);
+	
+	// Jieun add
+	if (commit_transaction->t_flush_trigger == 1) {
+		wake_up(&journal->j_wait_cpsetup);
+	}
 }
 
 void jbd2_journal_cpsetup_transaction(journal_t *journal)
diff --git kernel/x86_64/fs/jbd2/journal.c kernel/x86_64/fs/jbd2/journal.c
index 5d64785..eb45648 100755
--- kernel/x86_64/fs/jbd2/journal.c
+++ kernel/x86_64/fs/jbd2/journal.c
@@ -827,7 +827,10 @@ int jbd2_log_wait_commit(journal_t *journal, tid_t tid)
 				  tid, journal->j_commit_sequence);
 		wake_up(&journal->j_wait_commit);
 		read_unlock(&journal->j_state_lock);
-		wait_event(journal->j_wait_done_commit,
+//		wait_event(journal->j_wait_done_commit,
+//				!tid_gt(tid, journal->j_commit_sequence));
+		/* Jieun Modified */
+		wait_event(journal->j_wait_commit,
 				!tid_gt(tid, journal->j_commit_sequence));
 		read_lock(&journal->j_state_lock);
 	}
diff --git kernel/x86_64/fs/jbd2/revoke.c kernel/x86_64/fs/jbd2/revoke.c
index 0a078ae..16990f3 100755
--- kernel/x86_64/fs/jbd2/revoke.c
+++ kernel/x86_64/fs/jbd2/revoke.c
@@ -132,7 +132,7 @@ static void write_one_revoke_record64(journal_t *, transaction_t *,
 				struct list_head *,
 				struct buffer_head **, int*,
 				struct jbd2_revoke_record_s *, long long);
-static void flush_descriptor64(journal_t *, struct buffer_ehad *, int, long long);
+static void flush_descriptor64(journal_t *, struct buffer_head*, int, long long);
 #endif
 
 /* Utility functions to maintain the revoke table */
diff --git kernel/x86_64/fs/jbd2/transaction.c kernel/x86_64/fs/jbd2/transaction.c
index d3c71ab..48a6cbe 100755
--- kernel/x86_64/fs/jbd2/transaction.c
+++ kernel/x86_64/fs/jbd2/transaction.c
@@ -109,6 +109,8 @@ jbd2_get_transaction(journal_t *journal, transaction_t *transaction)
 	/* UFS */
 	INIT_LIST_HEAD(&transaction->io_bufs);
 	INIT_LIST_HEAD(&transaction->log_bufs);
+	// Jieun add
+	transaction->t_flush_trigger = 1;
 #ifdef DELAYED_COMMIT
 	INIT_LIST_HEAD(&transaction->t_jh_wait_list);
 #endif
diff --git kernel/x86_64/include/linux/blk_types.h kernel/x86_64/include/linux/blk_types.h
index c72f3da..8915455 100755
--- kernel/x86_64/include/linux/blk_types.h
+++ kernel/x86_64/include/linux/blk_types.h
@@ -43,11 +43,11 @@ struct bio {
 	/*unsigned long		bi_rw;*/		/* bottom bits READ/WRITE,
 						 * top bits priority
 						 */
+	unsigned short		epoch_id_1;
+	unsigned short		epoch_id_2;
+	short			stream_id_1;
+	short			stream_id_2;
 
-	pid_t			bi_stream_id;	/* kms91 added 19.04.04 - stream id (PID)
-						 * This variable store process id (PID) as stream id
-						 * So, type of this var is pid_t (signed int)
-						 */
 
 	unsigned short		bi_vcnt;	/* how many bio_vec's */
 	unsigned short		bi_idx;		/* current index into bvl_vec */
diff --git kernel/x86_64/include/linux/nvme.h kernel/x86_64/include/linux/nvme.h
index f95b775..8088db7 100755
--- kernel/x86_64/include/linux/nvme.h
+++ kernel/x86_64/include/linux/nvme.h
@@ -220,11 +220,12 @@ struct nvme_rw_command {
 	__u16			command_id;
 	__le32			nsid;
 	//__u64			rsvd2;		/* kms91 edit - __u32 for epoch_id, __s32 for stream_id */
-	__s32			cmd_stream_id;	/* kms91 added 19.04. 05 - stream id
-						 * It stores Process id (PID) as stream id
-						 * type is signed int (=pid_t)
-						 */
-	__u32			cmd_epoch_id;	/* kms91 added 19.03.18 - epoch id */
+	//__u32			cmd_epoch_id;	/* kms91 added 19.03.18 - epoch id */
+	__u16			eid_1;
+	__u16			eid_2;
+	__s16			sid_1;
+	__s16			sid_2;
+
 	__le64			metadata;
 	__le64			prp1;
 	__le64			prp2;
diff --git kernel/x86_64/include/linux/sched.h kernel/x86_64/include/linux/sched.h
index 6c75fcf..66972e4 100755
--- kernel/x86_64/include/linux/sched.h
+++ kernel/x86_64/include/linux/sched.h
@@ -1452,6 +1452,8 @@ struct task_struct {
         struct epoch *__epoch;
 	unsigned int barrier_fail;
 	unsigned int epoch_fail;
+	unsigned short epoch_count;
+	int queue_idx; //Jieun add for epoch queue pinning
 	//struct list_head epoch_pending;
 	//struct list_head epoch_dispatch;
 	//struct list_head epoch_complte;
diff --git kernel/x86_64/include/uapi/linux/blktrace_api.h kernel/x86_64/include/uapi/linux/blktrace_api.h
index 3b324eb..7dfdbef 100755
--- kernel/x86_64/include/uapi/linux/blktrace_api.h
+++ kernel/x86_64/include/uapi/linux/blktrace_api.h
@@ -107,8 +107,12 @@ struct blk_io_trace {
 	__u32 cpu;		/* on what cpu did it happen */
 	__u16 error;		/* completion error */
 	__u16 pdu_len;		/* length of data after this trace */
-	__u32 epoch;		/* Epoch ID - kms91 added 19.02.18 */
-	__s32 stream;		/* Stream ID - kms91 added 19.04.08 */
+	__u16 epoch_1;		/* Epoch ID 1 -Jieun add */
+	__u16 epoch_2;		/* Epoch ID 2 -Jieun add */
+	__s16 stream_1;		/* Stream ID 1 -Jieun add */
+	__s16 stream_2;		/* Stream ID 2 -Jieun add */
+	//__u32 epoch;		/* Epoch ID - kms91 added 19.02.18 */
+	//__s32 stream;		/* Stream ID - kms91 added 19.04.08 */
 };
 
 /*
diff --git kernel/x86_64/kernel/fork.c kernel/x86_64/kernel/fork.c
index 6852035..c1e9f43 100755
--- kernel/x86_64/kernel/fork.c
+++ kernel/x86_64/kernel/fork.c
@@ -317,7 +317,8 @@ static struct task_struct *dup_task_struct(struct task_struct *orig)
 	tsk->epoch_fail = 0;
 
 	tsk->stack = ti;
-
+	tsk->epoch_count = 0;
+	tsk->queue_idx = -1; //Jieun add
 	setup_thread_stack(tsk, orig);
 	clear_user_return_notifier(tsk);
 	clear_tsk_need_resched(tsk);
diff --git kernel/x86_64/kernel/trace/blktrace.c kernel/x86_64/kernel/trace/blktrace.c
index e6eee75..fece3b0 100755
--- kernel/x86_64/kernel/trace/blktrace.c
+++ kernel/x86_64/kernel/trace/blktrace.c
@@ -353,14 +353,23 @@ record_it:
 		t->error = error;
 		t->pdu_len = pdu_len;
 
-		/* kms91 added */
+		/* Jieun added */
 		if (pbio->bi_rw & REQ_ORDERED) {
-			t->stream = pbio->bi_stream_id;
-			t->epoch = pbio->bi_epoch->eid;
+			//t->stream = pbio->bi_stream_id;
+			//t->epoch = pbio->bi_epoch->eid;
+			t->stream_1 = pbio->stream_id_1;
+			t->stream_2 = pbio->stream_id_2;
+			t->epoch_1 = pbio->epoch_id_1;
+			t->epoch_2 = pbio->epoch_id_2;
 		}
 		else {
-			t->stream = 0;
-			t->epoch = 0;
+			//t->stream = 0;
+			//t->epoch = 0;
+
+			t->stream_1 = 0;
+			t->stream_2 = 0;
+			t->epoch_1 = 0;
+			t->epoch_2 = 0;
 		}
 
 		if (pdu_len)
diff --git kernel/x86_64/mm/filemap.c kernel/x86_64/mm/filemap.c
index 20a1f34..8e3c9f4 100755
--- kernel/x86_64/mm/filemap.c
+++ kernel/x86_64/mm/filemap.c
@@ -331,7 +331,8 @@ EXPORT_SYMBOL(filemap_write_and_dispatch_range);
 int filemap_ordered_write_range(struct address_space *mapping, loff_t start,
 				loff_t end)
 {
-	return __filemap_fdatawrite_range(mapping, start, end, WB_BARRIER_ALL);
+		return __filemap_fdatawrite_range(mapping, start, end, WB_BARRIER_ALL);
+//	return __filemap_fdatawrite_range(mapping, start, end, WB_ORDERED_ALL); //Jieun add
 }
 EXPORT_SYMBOL(filemap_ordered_write_range);
 
